{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e2274a",
   "metadata": {},
   "source": [
    "# Task for session2_cont and session3: \n",
    "## Edge-Preserving Denoising Filters & Feature Matching\n",
    "\n",
    "**Instructions:**  \n",
    "**please dont use .py to solve this task, just use tasks2.ipynb and edit the cells.**\n",
    "- After forking the [SkyXperts-Vision-Course repo](https://github.com/ffathy-tdx/SkyXperts-Vision-Course) on GitHub. (you should have already dont this in the last session & uploaded task1)\n",
    "- Go to your fork of the repo on GitHub.\n",
    "- At the top, look for a yellow box that says “This branch is X commits behind…”\n",
    "- Click the Sync fork or Update branch button.\n",
    "The new task will show up in your tasks/ folder.  \n",
    "- Upload your task to your forked repo (like you've done with task1 before)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf58e9e5",
   "metadata": {},
   "source": [
    "## 1. DoG, LoG, and Edge-Preserving Denoising Filters\n",
    "\n",
    "**Task:**\n",
    "- Briefly read the descriptions below, then apply each filter to `'sample.jpg'` (or any test image you choose).\n",
    "- Compare the results visually and write your observations.\n",
    "\n",
    "**Background:**\n",
    "- **DoG (Difference of Gaussian):** Used for edge detection by subtracting two blurred versions of the image (with different Gaussian sigmas).\n",
    "- **LoG (Laplacian of Gaussian):** Uses a single Gaussian blur followed by Laplacian to highlight regions of rapid intensity change (edges).\n",
    "- **Edge-Preserving Denoising (Bilateral Filter):** Smooths image while preserving edges (unlike simple Gaussian blur). You've already used this at the end of task1.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7c88459",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import required libraries\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread('sample.jpg', 0)  # Use grayscale for filtering\n",
    "plt.imshow(img, cmap='gray'); plt.axis('off'); plt.title('Original Image'); plt.show()\n",
    "\n",
    "# TODO: Apply DoG\n",
    "blur1 = cv2.GaussianBlur(img, (5,5), 1)\n",
    "blur2 = cv2.GaussianBlur(img, (5,5), 2)\n",
    "dog = blur1 - blur2\n",
    "# TODO: Apply LoG\n",
    "log = cv2.Laplacian(blur, cv2.CV_64F)\n",
    "# TODO: Apply bilateral (edge-preserving) filter\n",
    "blur = cv2.GaussianBlur(img, (5,5), 1)\n",
    "# Show all results for comparison\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,3,1); plt.imshow(blur, cmap=\"gray\"); plt.title(\"Gaussian Blur\")\n",
    "plt.subplot(1,3,2); plt.imshow(log, cmap=\"gray\"); plt.title(\"LoG\")\n",
    "plt.subplot(1,3,3); plt.imshow(dog, cmap=\"gray\"); plt.title(\"DoG\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b653404",
   "metadata": {},
   "source": [
    "**Q1: What differences do you observe between DoG, LoG, and the edge-preserving filter?**\n",
    "\n",
    "_Write your observations here._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec143be",
   "metadata": {},
   "source": [
    "## 2. Keypoints & Descriptors: SIFT vs. ORB\n",
    "\n",
    "**Task:**\n",
    "- Detect and plot keypoints on `'sample.jpg'` using SIFT and ORB.\n",
    "- Compare the number and distribution of detected keypoints.\n",
    "\n",
    "**Background:**\n",
    "- **Keypoints:** Distinctive image points (corners/blobs) useful for matching.\n",
    "- **Descriptors:** Vectors that describe local patches around keypoints for comparison/matching.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f507ad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect and plot SIFT keypoints\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Detect and plot ORB keypoints\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# TODO: Count and compare number of keypoints for SIFT and ORB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de463ee",
   "metadata": {},
   "source": [
    "**Q2: How do the number and distribution of keypoints differ between SIFT and ORB?**\n",
    "\n",
    "_Write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b06ae",
   "metadata": {},
   "source": [
    "## 3. Feature Matching with Descriptors\n",
    "\n",
    "**Task:**\n",
    "- Load a second image (e.g., `'sample2.jpg'`).\n",
    "- Detect keypoints/descriptors using SIFT or ORB in both images.\n",
    "- Match the features between the images using BFMatcher or FLANN.\n",
    "- Plot the top matches.\n",
    "\n",
    "**Background:**\n",
    "- **Feature matching** helps recognize objects/scenes or estimate image transformations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "046817e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load second image\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m img2 \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample2.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Detect SIFT keypoints/descriptors in both images\u001b[39;00m\n\u001b[0;32m      5\u001b[0m sift_Detector \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mSIFT_create()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# Load second image\n",
    "img2 = cv2.imread('sample2.jpg', 0)\n",
    "\n",
    "# Detect SIFT keypoints/descriptors in both images\n",
    "sift_Detector = cv.SIFT_create()\n",
    "sift_keypoints, descriptors = sift_Detector.detectAndCompute(gray.astype(np.uint8), None)\n",
    "\n",
    "# BFMatcher with default params\n",
    "bf = cv2.BFMatcher()\n",
    "matcher = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True) \n",
    "matches = matcher.match(query_descriptors,train_descriptors)\n",
    "# Draw matches\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "numberofmatches = 20\n",
    "img3 = cv.drawMatches(query_img,query_keypoints,train_img,train_keypoints,matches[:numberofmatches],None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "cv.imshow(\"matched image\", img3)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "# bonus TODO: Try with ORB or FLANN if you like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9cbd0b",
   "metadata": {},
   "source": [
    "**Q3: What do you notice about the feature matches? Are there any mismatches or errors? How might you improve the matching process?**\n",
    "\n",
    "_Write your answer here.\n",
    "Detect keypoints (LOG/DoG/SIFT).\n",
    "Describe them with SIFT descriptors (better than raw intensity).\n",
    "Match with BFMatcher or FLANN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0709b3",
   "metadata": {},
   "source": [
    "**Bonus Task (Optional, for extra credit):**\n",
    "- Try using different image preprocessing steps *before* edge detection or feature extraction.\n",
    "    - For example:\n",
    "        - Add noise to your image (e.g., Gaussian noise, salt-and-pepper noise).\n",
    "        - Apply a sharpening filter to your image.\n",
    "    - Then, run DoG, LoG, or any edge-preserving filter and observe the changes.\n",
    "- **What to do:**\n",
    "    - Show the results (images/plots) for at least one type of preprocessing + edge detection.\n",
    "    - Briefly explain:\n",
    "        - How does noise affect edge maps or keypoints?\n",
    "        - Does sharpening make features easier or harder to detect/match?\n",
    "\n",
    "**You can add your code and observations in the cells below.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f17a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf113b2",
   "metadata": {},
   "source": [
    "_What are your observations?_\n",
    "write them here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af90a09a",
   "metadata": {},
   "source": [
    "## 4. Reflection (Optional)\n",
    "\n",
    "- What was the most challenging or interesting part of this task for you?\n",
    "- Any feedback or thoughts?\n",
    "\n",
    "_Write your reflection here._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
